
# MCP是什么
model context Protocol（模型上下文协议）

在智能体应用项目开发中可以发现，集成AI模型复杂，
现有框架如LangChain Tools、LlamaIndex和Vercel AI SDK存在问题。
LangChain和LlamaIndex代码抽象高，商业化过重；Vercel AI SDK与Nextjs绑定过深。


MCP的优势：一是开放标准利于服务商开发API，
            二是避免重复造轮子，可利用现有MCP服务增强Agent。



MCP，全称是 Model Context Protocol，可以理解为 AI 应用和外部数据源、工具之间的一个‘标准化连接器’。
它的主要目标是让大语言模型能够以一种安全、可控、标准化的方式访问和利用外部资源


**解决的核心问题：**
模型“与世隔绝”：大语言模型本身的知识是静态的，无法直接获取实时数据（如天气、股价）或操作外部系统（如发送邮件、查询数据库）。
定制化开发成本高：过去，每个应用（如ChatGPT的插件、Cursor的AI功能）都需要为不同的数据源和工具开发特定的连接器，重复造轮子，且难以维护。
安全与权限控制：直接让模型访问外部资源存在安全风险，缺乏精细的权限管理。



**核心工作机制**
客户端-服务器架构：
客户端：通常是你的 AI 应用或 IDE（如 Cursor, Claude Desktop）。它实现了 MCP 协议，知道如何发送请求。
服务器：提供资源或工具的“供应商”。例如，一个提供数据库查询服务的服务器，一个提供公司内部 API 的服务器。
标准化协议：MCP 定义了一套标准的通信格式（基于 JSON-RPC），规定了客户端和服务器之间可以“说”哪些“话”（即调用哪些方法）。
两大核心能力：
工具：模型可以调用服务器提供的函数。例如，调用 search_web工具进行网络搜索，调用 sql_query工具执行数据库查询。
资源：模型可以订阅服务器提供的动态数据流。例如，订阅服务器日志、监控指标或实时新闻摘要。

**举例说明 & 关联实际**
“举个例子，假设我们正在开发一个智能客服助手。
没有 MCP 时：我们需要为这个助手单独编写连接公司用户数据库、订单系统、邮件发送服务的代码，这个过程很繁琐。

使用 MCP 后：公司可以部署几个 MCP 服务器：一个‘用户信息服务器’、一个‘订单查询服务器’、一个‘邮件发送服务器’。
我们的智能客服应用（MCP 客户端）只需要通过标准的 MCP 协议，就可以安全地调用这些服务器提供的工具
（如 get_user_info, query_order, send_email），极大地降低了集成复杂度，也方便了权限管理。”

**表达个人观点与价值**
它的价值：
标准化与生态：
类似于 Docker 标准化了应用交付，MCP 有望标准化 AI 与外部环境的交互，形成一个丰富的工具生态。
安全可控：服务器可以精确控制暴露给模型的资源和权限，比直接给模型 API Key 更安全。
开发者友好：开发者可以专注于编写好用的“工具服务器”，然后任何兼容 MCP 的客户端（如 Claude, Cursor）都能直接使用。

与类似技术的对比（如果面试官感兴趣）：
vs. OpenAI 插件 / ChatGPT Actions：MCP 是开源、厂商中立的协议，不绑定于任何一家模型公司，更具通用性。
vs. LangChain Tools：LangChain 是一个高级框架，它也集成了很多工具。而 MCP 是一个更底层的协议标准。
LangChain 未来完全可以集成 MCP 服务器作为其工具来源。


**总结**
面试官，MCP（模型上下文协议）本质上是一个连接AI模型和外部世界（如数据库、API、工具）的开源标准化协议
它采用客户端-服务器架构，核心目的是让大模型能安全、可控地调用外部工具和订阅动态数据，从而解决模型知识静态化、集成开发成本高的问题。
您可以把它理解成AI领域的“USB标准”——它定义了一套通用规范，
使得任何兼容MCP的应用（如Claude Desktop、Cursor）都能即插即用地使用各种由MCP服务器提供的资源，
极大地促进了工具生态的繁荣和开发的标准化。与特定厂商的解决方案（如OpenAI插件）相比，它的核心优势在于其中立性和开放性，
为构建更强大、更安全的AI应用提供了坚实的基础。


